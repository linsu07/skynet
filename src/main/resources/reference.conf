//  分布配置说明
//  分桶方式------binStyle的选项:"custom"给定自定义数组分组,"isometric"等距离分组
//  binStyle:{"custom":"1,10,20,30"}
//  binStyle:{"isometric":"10-1000"}
//  itemNumLimit:不配置该选项则不截断(非分桶)
//  itemNumBinLimit:不配置该选项则不截断(分桶)
//  如果有条件的需求可参考如下配置expr: "ads_details.click_num>0"

HourModel{
  class:org.apache.spark.ml.search.features.HourModel
  inputCols:[ts]
  outputCols:[hour]
}

DayOfWeekModel{
  class:org.apache.spark.ml.ad.features.DayOfWeekModel
  inputCols:[ts]
  outputCols:[dayOfWeek]
}
IPsegModel{
  class:org.apache.spark.ml.search.features.IPsegModel
  inputCols:[ip]
  outputCols:[IPSeg]
}
AgeModel{
  class:org.apache.spark.ml.search.features.AgeModel
  inputCols:[guid,ts]
  outputCols:[age,lifestage]
}
AdClickHour {
  class: org.apache.spark.ml.ad.features.AdClickHourTF
  name: AdClickHour
  itemNumLimit:-1
  inputCols: [ads_details.ad_clickdetails.click_time]
  outputCols: [adclick.hour]
}

DistributeFeature{
  class:org.apache.spark.ml.ad.entropy.DistributeFeature
}

AdIndustryDistributeFeature{
  class:org.apache.spark.ml.ad.entropy.AdIndustryDistributeFeature
}

RedistributeByFrequency{
  class:org.apache.spark.ml.ad.entropy.RedistributeByFrequency
  binDesc:[1,2,3,4,5,6,7,8,9,10,15,30,100,1000,1001]
}
UserActionChainModel{
  class: org.apache.spark.ml.ad.features.UserActionChainModel
  inputCols: [src, t, ts]
  outputCols: [action_list, time_list]
  search1: ["chrome_address_bar","lm", "home_.*", "se[0-9|_].*", "360.*", "corr_.*", "hao.*", "recom-nlp.*", "oneboxlink.*", "internal_.*"]
  search2: ["srp.*", "res-sug.*", "sug-local", "tab_.*", "inline.*"]
  paging: ["srp_paging"]
  right_sug: ["know_side_nl.*"]
  related: ["related_.*", "pdr_guide.*", "inline-recommend_.*"]
}
SrcExtractModel{
  class: org.apache.spark.ml.ad.features.SrcExtractModel
  inputCols: [src]
  outputCols: [src_normed]
  src_list:[
    {name:search1_lm,expr:"lm"}    // 联盟搜索框
    ,{name:search1_home,expr:"home_.*"}   //大搜主页
    ,{name:search1_own_SecurityBrowser,expr:"se[0-9|_].*"}  // 安全浏览器
    ,{name:search1_own_quickBrowser,expr:"360.*"}  // 极速浏览器
    ,{name:search1_own_correct,expr:"corr_.*"}   //纠错
    ,{name:search1_own_navigator,expr:"hao.*"}  // 导航
    ,{name:search1_own_recommend,expr:"recom-nlp.*"}  //个性化推荐
    ,{name:search1_own_box,expr:"oneboxlink.*"}  //box流量
    ,{name:search1_own_internal,expr:"internal_.*"}  //内部其他产品导量
    ,{name:search2,expr:"srp.*"}  //结果页衍生
    ,{name:search2_suggest,expr:"res-sug.*"}  //结果页衍生下拉推荐
    ,{name:search2_suggest,expr:"sug-local"}  //结果页衍生下拉推荐
    ,{name:search2_tab,expr:"tab_.*"}  //结果页衍生 ，新tab
    ,{name:search2_recommend,expr:"inline.*"}  //结果页衍生 ，推荐
    ,{name:search2_paging,expr:"srp_paging"}  //结果页衍生 ，推荐
    ,{name:search2_right_recommend,expr:"know_side_nl.*"}  //结果页衍生 ，右侧推荐
    ,{name:search2_related,expr:"related_.*"}  //结果页衍生 ，相关推荐
    ,{name:search2_top_recommend,expr:"pdr_guide.*"}  //结果页衍生 ，顶部推荐
  ]
}

BrowserExtractModel{
  class: org.apache.spark.ml.ad.features.BrowserExtractModel
  inputCols: [ua]
  outputCols: [browser]
}

UserActionIndexModel {
  class: org.apache.spark.ml.ad.features.UserActionIndexModel
  inputCols: [action_list, time_list]
  outputCols: [actionid_list]
  vocabulary=[
    "click:0"
    ,"t1:1"
    ,"search1:2"
    ,"t0:3"
    ,"search2:4"
    ,"t2:5"
    ,"end:6"
    ,"start:7"
    ,"t3:8"
    ,"t4:9"
    ,"t5:10"
    ,"unk:11"
    ,"related:12"
    ,"adclick:13"
    ,"right_sug:14"
    ,"t-1:15"
  ]
  includeThinktime: true
}
ActionEntropy{
  class: org.apache.spark.ml.ad.entropy.ActionEntropy
  inputCols: [actionid_list]
  outputCols:["ActionEntropyScore","ActionEntropy","totalActionList","ActionListPatternNumber","anomalyActionList","anomalyActionListScores"]
  anomalyScoreThreshold:0.6
}

CTR {
  class: org.apache.spark.ml.ad.Groupfeatures.CTR
  # inputCols 是每个算法的必填项
  inputCols: [tp, click_num,ads_clicknum,ads_num]
  outputCols: [suv, spv, cuv, cpv, aduv, adpv]
  hiddenDims: [srcg]
  statLowerLimits: 200
}

ActionSpeedModel{
  class:org.apache.spark.ml.ad.guid.ActionSpeedModel
  inputCols:[time_list]
  sequenceCount:4
  defaultSpeed:10
  outputCols:[speedOn4Action]
}

IForestModel{
  class:org.apache.spark.ml.algo.density.IForestModel
  inputCols:[]
  threshold:0.7
}


SearchEntranceTypeModel{
  class:org.apache.spark.ml.ad.features.SearchEntranceTypeTF
  search1: ["chrome_address_bar","lm", "home_.*", "se[0-9|_].*", "360.*", "corr_.*", "hao.*", "recom-nlp.*", "oneboxlink.*", "internal_.*"]
  inputCols:[src]
  outputCols:[srcType]
}

LifeStageAddTF{
  class:org.apache.spark.ml.ad.Groupfeatures.NumericFeatureAddTF
  name:"lifeStage_count"
  inputCols:["lifestage|lifestage==young","lifestage|lifestage==old"]
  outputCols:[youngLifeStageCount,oldLifeStageCount]
}

YoungLifeStageRateFeature {
  class: org.apache.spark.ml.ad.Groupfeatures.FeaBasicOperationTF
  name: SugFinalCount
  expression: "youngLifeStageCount/SPV"
  outputCols: [youngLifeStageRate]
}

NumericFeatureAdd{
  class:org.apache.spark.ml.ad.Groupfeatures.NumericFeatureAddTF
}

FeaScoreFeatureADD{
  class: org.apache.spark.ml.ad.Groupfeatures.FeaScoreTF
}

FeaBasicOperationFeatureADD{
  class: org.apache.spark.ml.ad.Groupfeatures.FeaBasicOperationTF
}



FeaDistributeFeatureADD{
  class: org.apache.spark.ml.ad.Groupfeatures.FeaDistributeTF
}

DiscreteFeatureAdd{
  class: org.apache.spark.ml.ad.Groupfeatures.DiscreteFeatureAddTF
  //  inputCols与outputCols需要一一对应， 如果是多级结果则使用.分割 （如ads_details.industry），如有简单的条件判断（只支持>0判断）则字段后加|后接判断字段
  //  MaxValue:true  // 是否获取最大value
  //  MinValue:true //是否获取最小value
  //  MeanValue:true //是否获取平均value
  //  DevValue:true // 是否获取标准差
}

GuidTimeGap{
  class: org.apache.spark.ml.ad.entropy.GuidTimeGap
  timeStepMilliSecond:3000   #划分用户思考时间差几秒为一个区间
  maxStep:41  #如果用户思考超过了gap 20 则gap=20
  sessionGap:900   #this must be an integral multiple of (timeStepMilliSecond/1000)
  statLowerLimits:10000 #渠道内用户动作的最小统计量级
  inputCols:[time_list]
  outputCols:[actionTimeGapscore]
}

//UserActionTimeGap{
//  class: org.apache.spark.ml.ad.entropy.UserActionTimeGap
//  standardDistribution:[0.19336,0.10905,0.07714,0.06065,0.04940,0.04152,0.03453,0.02907,0.02472,0.02141,0.01876,0.01578,0.01353,0.01194,0.01065,0.00960,0.00870,0.00789,0.00718,0.00658,0.24856]
//  inputCols:[time_list]
//  outputCols:[actionTimeGapscore]
//  timeStepMilliSecond:3000   #划分用户思考时间差几秒为一个区间
//  maxStep:21  #如果用户思考超过了gap 20 则gap=20
//  sessionGap:900   #this must be an integral multiple of (timeStepMilliSecond/1000)
//  statLowerLimits:5000 #渠道内用户动作的最小统计量级
//
//}


Check{
  class: org.apache.spark.ml.ad.Check
  name:unk
  inputCols: [unk]
  outputCols:[unk]
  //  spamExpr:
  //  anomalyExpr:
}




//UserActionCounts{
//class: org.apache.spark.ml.ad.entropy.UserActionCounts
//standardDistribution:[0.146151716,0.23687711,0.094916873,0.093627124,0.055947182,0.051165741,0.036213095,0.032291183,0.025311659,0.022686914,0.018821629,0.016945164,0.014276536,0.012714703,0.011142889,0.010052859,0.008916386,0.008224929,0.007259345,0.096456963]
//inputCols:[action_list]
//outputCols:[actionCountScore,actionBin]
//PVBin:1   # PVBin 如果发生变更，则需要重新提供standardDistribution，目前的标准分布就是值为1的标准分布
//MaxBin:21   # (UserMaxPV/PVBin).floor +1
//UserMaxPV:20   #用户搜索次数最大是多少次，超过了限制的用户不计入渠道统计
//statLowerLimits:5000 #渠道内用户动作的最小统计量级
//}

GuidActionCount{
  class: org.apache.spark.ml.ad.entropy.GuidActionCount
}


ConditionalFeature{
  class :org.apache.spark.ml.ad.Groupfeatures.ConditionalFeature
  //  outputCols:["unk"]
  //  ifExpr:"if ()"
  //  ifValueExpr:"some value"
  //  elseifExpr:" else if ()"
  //  elseifValueExpr:" some value"
  //  defaultValue:"some value"
}
AdClickPosMerge{
  class: org.apache.spark.ml.ad.entropy.AdClickPosMerge
  outputCols:[adclickLocationStat]
  inputCols:[ads_details.location,ads_details.pos,ads_details.ad_clicknum]
}
AdClickViewGap{
  class: org.apache.spark.ml.ad.entropy.AdClickViewGap
}

AdClickPosXY{
  class: org.apache.spark.ml.ad.entropy.AdClickPosXY
  binDesc:[50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1150,1200,1201]
}
RemoveDuplicatedAdid{
  class: org.apache.spark.ml.ad.guid.RemoveDuplicatedAdid
}

AdAdvertIdDiscreteFeatureAddTF{
  class: org.apache.spark.ml.ad.Groupfeatures.AdAdvertIdDiscreteFeatureAddTF
}



IForestAddTF{
  class: org.apache.spark.ml.algo.density.IForestModel
  //model_addr:"D:\\work\\testdata\\iforest\\model_Final_20200525_step_5\\day20200525round1badrate8"
  model_addr:"/home/hdp-saonline-w/searchvalue/ad/algoModelStandard/IforestModel"
}

MahaDistanceTF{
  class: org.apache.spark.ml.algo.distance.MahaDistanceModel
  //model_addr:"D:\\work\\testdata\\iforest\\model_Final_20200525_step_5\\day20200525round1badrate8"
  model_addr:"/home/hdp-saonline-w/searchvalue/ad/algoModelStandard/MahaDistanceModel"
}

FirstSearchHasPqCheck {
  class: org.apache.spark.ml.pc.searchbehavior.FirstSearchHasPqCheck
  inputCols:[src, pq]
}


SearchCrawler{
  class: org.apache.spark.ml.search.searchbehavior.SearchCrawler
  inputCols:[q]
  spamQueryNum:100
  spamRepeatNum:20
  maxQueryThreshold:30
  maxRepeatThreshold:7
  statLowerLimits:200
}


IdlePeriod{
  class:org.apache.spark.ml.pc.timelocation.IdlePeriod
  inputCols:[hour,srcg,site,t]   // srcg 标识是对search进行处理，如果是click则需要填click_num
  ministat:10
  upperTimeThreshold:24
  lowerTimeThreshold:8
  statLowerLimits:10000
  miniIdleHourThreshold:1
}

SearchtimeEntropy{
  class:org.apache.spark.ml.pc.timelocation.ActionTimeEntropy
  name: SearchtimeEntropy
  inputCols:[hour,srcg,site]   //srcg 标识是对search进行处理，如果是click则需要填click_num
  upperspamScoreThreshold:0.99
  lowerspamScoreThreshold:0.3
  upperanomalyScoreThreshold:0.985
  loweranomalyScoreThreshold:0.35
  statLowerLimits:200
  remit_bar:true
}


QueryIsDigital {
  class: org.apache.spark.ml.search.searchbehavior.QueryIsDigital
  inputCols:[q]
  QueryIsDigitalRatio:0.05
  statLowerLimits:1000
}


StandardFormatCheck4pc{
  class: org.apache.spark.ml.pc.searchbehavior.StandardFormatCheck
  inputCols:[guid,sid]
}

ClickSite {
  class: org.apache.spark.ml.pc.clickbehavior.ClickSite
  inputCols:[click_details]
  statLowerLimits:200
  spamScoreThreshold:0.8
  anomalyScoreThreshold:0.4
  topThreshold:3
}

QueryChangeTooQuick4pc{
  class: org.apache.spark.ml.pc.searchbehavior.QueryChangeTooQuick
  # inputCols 是每个算法的必填项
  inputCols:[tp,q,t]
  spamScoreThreshold:1000.0
  statLowerLimits:2
}

DsAbnormalCheck {
  class: org.apache.spark.ml.search.device.DsAbnormalCheck
  inputCols:[ds]
}

ClickPos4pc{
  class: org.apache.spark.ml.pc.clickbehavior.ClickPos
  # inputCols 是每个算法的必填项
  inputCols:[click_details]
  spamScoreThreshold:0.8
  sideScoreThreshold:0.3
  anomalyScoreThreshold:0.7
  statLowerLimits:200
}


CityChangeTooQuick{
  class: org.apache.spark.ml.search.timelocation.CityChangeTooQuick
  inputCols:[ict]
  SpamThreshold:4.0
}


RemoveDuplicatedRequest{
  class: org.apache.spark.ml.pc.searchbehavior.RemoveDuplicatedRequest
}

SrcgSearchSameTimes{
  class: org.apache.spark.ml.pc.searchbehavior.SrcgSearchSameTimes
  # inputCols 是每个算法的必填项
  inputCols:[tp,srcg]
  qsearchLowerLimes:30
  statLowerLimits:3
  max_gap:10
}